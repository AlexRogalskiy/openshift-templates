apiVersion: v1
kind: Template
metadata:
  name: alertmanager
  annotations:
    "openshift.io/display-name": Prometheus - Alertmanager
    description: |
      A monitoring solution for an OpenShift cluster - collect and gather metrics and alerts from nodes, services, and the infrastructure. This is a tech preview feature.
    iconClass: fa fa-cogs
    tags: "monitoring, prometheus, alertmanager, time-series"
parameters:
  - name: APP_NAME
    description: "Value for app label."
 
  - name: NAME_SPACE
    description: "The name of the namespace (openshift project)"
 
  - name: REPLICAS
    description: "number of Alertmanager replicas"
 
objects:
 
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: alertmanager
 
- apiVersion: v1
  kind: Service
  name: alertmanager
  metadata:
    labels:
      app: ${APP_NAME}
    name: alertmanager
    namespace: "${NAME_SPACE}"
  spec:
    ports:
    - name: alertmanager
      port: 9093
      protocol: TCP
      targetPort: alert-port
    selector:
      app: ${APP_NAME}
 
 
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
    labels:
      app: ${APP_NAME}
    name: alertmanager
    namespace: "${NAME_SPACE}"
  spec:
    port:
      targetPort: alertmanager
    to:
      kind: Service
      name: alertmanager
      weight: 100
    tls:
      termination: edge
    wildcardPolicy: None
 
- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: alertmanager
  spec:
    podManagementPolicy: Parallel
    updateStrategy:  
      type: RollingUpdate
    selector:
      matchLabels:
        app: alertmanager
    replicas: ${REPLICAS}
    template:
      metadata:
        labels:
          app: ${APP_NAME}
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9093"
          prometheus.io/scheme: http
          prometheus.io/scrape: "true"
      spec:
        serviceAccountName: alertmanager
        containers:
          - name: alertmanager
            args:
              - --storage.path=/alertmanager/data/
              - --config.file=/etc/alertmanager/alertmanager.yml
              - --web.external-url=https://alertmanager-demo-org.com
            image: prom/alertmanager:v0.21.0
            resources:
              limits:
                cpu: "500m"
                memory: "128Mi"
              requests:
                cpu: "250m"
                memory: "64Mi"
            ports:
            - name: alert-port
              containerPort: 9093
            - name: cluster-port
              containerPort: 9094
            readinessProbe:
              failureThreshold: 3
              httpGet:
                path: /-/ready
                port: 9093
                scheme: HTTP
              initialDelaySeconds: 60
              periodSeconds: 5
              successThreshold: 1
              timeoutSeconds: 1
            livenessProbe:
              failureThreshold: 3
              httpGet:
                path: /-/healthy
                port: 9093
                scheme: HTTP
              initialDelaySeconds: 60
              periodSeconds: 5
              successThreshold: 1
              timeoutSeconds: 1
            volumeMounts:
              - name: alertmanager-data
                mountPath: /alertmanager/data/
              - name: alertmanager-config-dir
                mountPath: /etc/alertmanager
          - name: configmap-reload
            image:  jimmidyson/configmap-reload:v0.4.0
            imagePullPolicy: "IfNotPresent"
            args:
              - --volume-dir=/etc/alertmanager
              - --webhook-url=http://localhost:9093/-/reload
            volumeMounts:
            - name: alertmanager-config-dir
              mountPath: /etc/alertmanager
              readOnly: true
        volumes:
          - name: alertmanager-config-dir
            configMap:
                defaultMode: 420
                items:
                - key: alertYaml
                  path: alertmanager.yml
                name: alertmanager-config-map
    volumeClaimTemplates:
    - metadata:
        name: alertmanager-data
      spec:
        accessModes: [ "ReadWriteMany" ]
        resources:
          requests:
            storage: 2Gi
 
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: alertmanager-config-map
  data:
      alertYaml: |-
        ---
        # Alerting rules
        #
        # Required labels:
        #   alertname
        #   severity    (critical, warning, information)
        #   service     (prometheus, okd, rabbit, redis, kafka, application)
        #   scope       (monitoring, infrastructure, messaging, db)
        # Optional Labels:
        #   target      (downstream)
        #   environment (stage, production)

        global:

          # The smarthost and SMTP sender used for mail notifications.
          smtp_smarthost: 'smtp-relay-prod.org.com:25' 
          smtp_from: 'app-alerts@org.com'
          smtp_require_tls: False
        
        # The root route on which each incoming alert enters.

        route:

          # The labels by which incoming alerts are grouped together. For example,
          # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
          # be batched into a single group.

          group_by: ['alertname', 'severity', 'scope']

          # When a new group of alerts is created by an incoming alert, wait at
          # least 'group_wait' to send the initial notification.
          # This way ensures that you get multiple alerts for the same group that start
          # firing shortly after another are batched together on the first
          # notification.

          group_wait: 30s

          # When the first notification was sent, wait 'group_interval' to send a batch
          # of new alerts that started firing for that group.

          group_interval: 5m

          # If an alert has successfully been sent, wait 'repeat_interval' to
          # resend them.

          repeat_interval: 4h

          # The root route must not have any matchers as it is the entry point for
          # all alerts. It needs to have a receiver configured so alerts that do not
          # match any of the sub-routes are sent to someone.
          # severity page - will only send email to apps team
          # severity alert - will send email and pager duty notifications to apps team
          # severity notification - will send email notification to pep team
          # severity warning - will send email and pager duty notification to pep team

          receiver: 'catch-all-email-receiver'

          routes:
            - match:
                environment: stage
              repeat_interval: 8h
              receiver: 'non-prod-email-receiver'
              continue: false                       
            
            # Literally anything with the word 'down'
            - match_re:
                alertname: ^(Down|down)$
              repeat_interval: 2h
              receiver: 'infra-email-receiver'
              continue: true                                 # Whether an alert should continue matching subsequent sibling nodes. default is false

        receivers:

        - name: 'non-prod-email-receiver'
          email_configs:
            - to: 'non-prod-email-receiver@org.com'
              from: 'app-non-prod-alerts@org.com'
              send_resolved: true
 
        - name: 'critical-email-receiver'
          email_configs:
            - to: 'critical-email-receiver@org.com'
              from: 'app-critical-alerts@org.com'
              send_resolved: true                           # Whether or not to notify about resolved alerts. default is false
          
        - name: 'infra-email-receiver'
          email_configs:
            - to: 'infra-email-receiver@org.com'
              from: 'app-critical-alerts@org.com'
              send_resolved: true

        - name: 'catch-all-email-receiver'
          email_configs:
            - to: 'catch-all-email-receiver@org.com'
              send_resolved: true                            
 